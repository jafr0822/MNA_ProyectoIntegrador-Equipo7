{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aod6AM6QM7it"
      },
      "source": [
        "# Proyecto Integrador\n",
        "\n",
        "\n",
        "## Tecnológico de Monterrey\n",
        "### Maestría en Inteligencia Artificial Aplicada (MNA)\n",
        "#### Avance 4\n",
        "#### Equipo 7\n",
        "\n",
        "\n",
        "* Jorge Arturo Federico Rivera – A01250724\n",
        "* Marco Antonio Vázquez Morales – A01793704\n",
        "* Alejandro Jesús Vázquez Navarro - A01793146\n",
        "\n",
        "## Modelos Alternativos\n",
        "\n",
        "\n",
        "### Table of Contents\n",
        "1. [Preparación](##Preparación)\n",
        "2. [Comparativa](##Comparativa)\n",
        "3. [Ajuste Fino](##AjusteFino)\n",
        "\n",
        "Proyecto:\n",
        "\n",
        "*Modelo clasificador de multimorbilidad maternal y predictor de desenlaces perinatales a partir de datos clínicos metabólicos, genéticos y nutricionales de mujeres mexicanas*\n",
        "\n",
        "23 de mayo de 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMdtbPcvLN5E"
      },
      "source": [
        "#1. [Preparación](##Preparación)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBUwvY5DwR3q"
      },
      "source": [
        "# **1.1 Carga de Librerías**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SDzqIuHxwTwd"
      },
      "outputs": [],
      "source": [
        "#%pip install imbalanced-learn\n",
        "#%pip install scikit-learn tensorflow\n",
        "#%pip install scikeras\n",
        "#%pip install --upgrade scikit-learn\n",
        "#%pip uninstall scikit-learn imbalanced-learn\n",
        "#%pip install scikit-learn==1.0.2 imbalanced-learn==0.8.1\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, precision_recall_curve, auc, recall_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8Lu4uwdE5SA"
      },
      "source": [
        "# **1.2. Carga de datos**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "rJ75tgy5G_8N",
        "outputId": "8fa81ae2-45a3-4874-ab82-f415ef26f6b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EscalaRiesgo</th>\n",
              "      <th>biopsias</th>\n",
              "      <th>obs_h</th>\n",
              "      <th>ichos_pregesta</th>\n",
              "      <th>hta_pregesta</th>\n",
              "      <th>sop</th>\n",
              "      <th>hipotiroidismo</th>\n",
              "      <th>hipertiroidismo</th>\n",
              "      <th>consumo_alcohol</th>\n",
              "      <th>consumo_tabaco</th>\n",
              "      <th>...</th>\n",
              "      <th>sdg_parto</th>\n",
              "      <th>ant_aborto</th>\n",
              "      <th>macrosomia_rn_0</th>\n",
              "      <th>macrosomia_rn_0.0</th>\n",
              "      <th>macrosomia_rn_0/0</th>\n",
              "      <th>macrosomia_rn_1</th>\n",
              "      <th>macrosomia_rn_1.0</th>\n",
              "      <th>macrosomia_rn_1/0</th>\n",
              "      <th>macrosomia_rn_1/1</th>\n",
              "      <th>macrosomia_rn_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.747297</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.747297</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.747297</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.747297</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.420203</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 82 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  EscalaRiesgo  biopsias  obs_h  ichos_pregesta  hta_pregesta  sop  \\\n",
              "0            C         0      0               0             0    0   \n",
              "1            C         0      0               0             1    0   \n",
              "2            C         0      1               0             1    0   \n",
              "3            B         0      0               0             1    0   \n",
              "4            C         0      1               0             1    0   \n",
              "\n",
              "   hipotiroidismo  hipertiroidismo  consumo_alcohol  consumo_tabaco  ...  \\\n",
              "0               0                0                0               0  ...   \n",
              "1               0                0                0               0  ...   \n",
              "2               0                0                0               0  ...   \n",
              "3               0                0                0               0  ...   \n",
              "4               0                0                0               0  ...   \n",
              "\n",
              "   sdg_parto  ant_aborto  macrosomia_rn_0  macrosomia_rn_0.0  \\\n",
              "0        0.0   -0.747297                0                  0   \n",
              "1        0.0   -0.747297                0                  0   \n",
              "2        0.0   -0.747297                0                  0   \n",
              "3        0.0   -0.747297                0                  0   \n",
              "4        0.0    1.420203                0                  0   \n",
              "\n",
              "   macrosomia_rn_0/0  macrosomia_rn_1  macrosomia_rn_1.0  macrosomia_rn_1/0  \\\n",
              "0                  0                1                  0                  0   \n",
              "1                  0                1                  0                  0   \n",
              "2                  0                1                  0                  0   \n",
              "3                  0                1                  0                  0   \n",
              "4                  0                1                  0                  0   \n",
              "\n",
              "   macrosomia_rn_1/1  macrosomia_rn_2  \n",
              "0                  0                0  \n",
              "1                  0                0  \n",
              "2                  0                0  \n",
              "3                  0                0  \n",
              "4                  0                0  \n",
              "\n",
              "[5 rows x 82 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_path = r'data/data_limpia.csv'\n",
        "\n",
        "#Eliminamos columnas que no necesitaremos como identificarores y el número de clúster\n",
        "\n",
        "cols_to_remove = ['id_gdg', 'origen_px', 'IndexMorbilidad', 'anticonceptivo_0.0',\n",
        "       'anticonceptivo_0.6316526610644257', 'anticonceptivo_1.0',\n",
        "       'anticonceptivo_2.0', 'cluster']\n",
        "\n",
        "data = pd.read_csv(file_path, sep=\";\", encoding='utf-8', index_col=False)\n",
        "data  = data.drop(cols_to_remove , axis=1)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "37GVFqx0E_dp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data.drop('EscalaRiesgo', axis=1)\n",
        "y = data['EscalaRiesgo']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5XImi-VFL0_"
      },
      "source": [
        "# **1.3 Aplicar balanceo de clases via SMOTE**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNm_VXrLI6De"
      },
      "source": [
        "Esta técnica es recomendada cuando tenemos clases desbalanceadas. Nuestro problema tiene 3 clases:\n",
        "\n",
        "- A Para alto riesgo (la presencia de 3 o 4 factores multimorbilidad)\n",
        "- B Para medio riesgo (presencia de 1 o 2 factores multimorbilidad)\n",
        "- C Para riesgo nulo. (sin la presencia de factores de multimorbilidad)\n",
        "\n",
        "En temas de salud es importante tener clases balanceadas, esto nos permitirá tener los siguientes beneficios:\n",
        "\n",
        "- Mejora en la precisión del modelo; en este sentido, detectar una clase **A** con alto riesgo de morbilidad es crucial para que el modelo entregue valor al área médica.\n",
        "\n",
        "- Equidad en la atención médico. Debemos aseguramos que nuestro modelo sea justo y equitativo sobre todo en temas de salud. Un desbalance puede provocar sesgos y lecturas erróneas.\n",
        "\n",
        "- Generalización. Un modelo con clases balanceadas generalizará mejor cuando trate nuevos datos. En el dominio de conocimiento de salud humana, esto es relevante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMVI1KSnwULF"
      },
      "source": [
        "# 2. [Comparativa](##Comparativa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZAk_tQxT_MO"
      },
      "source": [
        "## Evaluación con TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Es necesario aplicar un LabelEncoder para la variable dependiente ya que es categórica y de tipo string en este momento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y Original\n",
            " 0    C\n",
            "1    C\n",
            "2    C\n",
            "3    B\n",
            "4    C\n",
            "Name: EscalaRiesgo, dtype: object\n",
            "y Encoded\n",
            "    0\n",
            "0  2\n",
            "1  2\n",
            "2  2\n",
            "3  1\n",
            "4  2\n"
          ]
        }
      ],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "y_encoded = pd.DataFrame(label_encoder.fit_transform(y))\n",
        "\n",
        "print(\"y Original\\n\", y.head(5))\n",
        "print(\"y Encoded\\n\", y_encoded.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Definir CNN\n",
        "\n",
        "La red neuronal se define con dos capas ocultas, cada una seguida de una Dropout layer para prevenir overfitting, lo cual es clave por la cantidad limitada de datos con los que se cuenta.. Por esta misma última razón, se utiliza regularización L2.\n",
        "\n",
        "Debido a que la variable dependiente es multi-clase, es necesario agregar una capa de salida de 4 unidades con una activación softmax que es la recomendada al hacer clasificaciones de este tipo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/deck/Documents/School/Proyecto Integrador/Repositorio/MNA_ProyectoIntegrador-Equipo7/.venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],),\n",
        "                 kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',  \n",
        "    metrics=['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entrenar modelo y hacer predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9912 - loss: 0.1061 - val_accuracy: 0.7188 - val_loss: 1.6070\n",
            "Epoch 2/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9859 - loss: 0.1195 - val_accuracy: 0.7143 - val_loss: 1.7468\n",
            "Epoch 3/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.1040 - val_accuracy: 0.7188 - val_loss: 1.6864\n",
            "Epoch 4/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.1209 - val_accuracy: 0.7188 - val_loss: 1.6385\n",
            "Epoch 5/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.1129 - val_accuracy: 0.7188 - val_loss: 1.6140\n",
            "Epoch 6/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0999 - val_accuracy: 0.7234 - val_loss: 1.6932\n",
            "Epoch 7/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.1198 - val_accuracy: 0.7256 - val_loss: 1.6499\n",
            "Epoch 8/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0985 - val_accuracy: 0.7143 - val_loss: 1.8156\n",
            "Epoch 9/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9948 - loss: 0.0910 - val_accuracy: 0.7143 - val_loss: 1.7736\n",
            "Epoch 10/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.1014 - val_accuracy: 0.7075 - val_loss: 1.7153\n",
            "Epoch 11/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9946 - loss: 0.0932 - val_accuracy: 0.7188 - val_loss: 1.8864\n",
            "Epoch 12/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9865 - loss: 0.1048 - val_accuracy: 0.7075 - val_loss: 1.7560\n",
            "Epoch 13/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0913 - val_accuracy: 0.7143 - val_loss: 1.7788\n",
            "Epoch 14/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.1109 - val_accuracy: 0.7120 - val_loss: 1.7624\n",
            "Epoch 15/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.1007 - val_accuracy: 0.7188 - val_loss: 1.8772\n",
            "Epoch 16/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0954 - val_accuracy: 0.7188 - val_loss: 1.8675\n",
            "Epoch 17/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 0.0934 - val_accuracy: 0.7143 - val_loss: 1.6727\n",
            "Epoch 18/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0916 - val_accuracy: 0.7166 - val_loss: 1.8806\n",
            "Epoch 19/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0967 - val_accuracy: 0.7143 - val_loss: 1.7847\n",
            "Epoch 20/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.1017 - val_accuracy: 0.7166 - val_loss: 1.9731\n",
            "Epoch 21/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0834 - val_accuracy: 0.7120 - val_loss: 1.8485\n",
            "Epoch 22/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0882 - val_accuracy: 0.7166 - val_loss: 2.0230\n",
            "Epoch 23/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0889 - val_accuracy: 0.7143 - val_loss: 1.7923\n",
            "Epoch 24/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0858 - val_accuracy: 0.7143 - val_loss: 2.0101\n",
            "Epoch 25/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.1098 - val_accuracy: 0.7166 - val_loss: 1.8741\n",
            "Epoch 26/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0872 - val_accuracy: 0.7120 - val_loss: 1.7955\n",
            "Epoch 27/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0832 - val_accuracy: 0.7143 - val_loss: 1.9152\n",
            "Epoch 28/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9951 - loss: 0.0844 - val_accuracy: 0.7143 - val_loss: 2.0184\n",
            "Epoch 29/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0891 - val_accuracy: 0.7143 - val_loss: 1.8273\n",
            "Epoch 30/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0861 - val_accuracy: 0.7143 - val_loss: 2.0780\n",
            "Epoch 31/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9939 - loss: 0.0841 - val_accuracy: 0.7120 - val_loss: 1.8622\n",
            "Epoch 32/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9946 - loss: 0.0816 - val_accuracy: 0.7120 - val_loss: 1.9023\n",
            "Epoch 33/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0746 - val_accuracy: 0.7188 - val_loss: 1.8799\n",
            "Epoch 34/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0783 - val_accuracy: 0.7120 - val_loss: 1.9632\n",
            "Epoch 35/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0781 - val_accuracy: 0.7166 - val_loss: 1.9960\n",
            "Epoch 36/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0776 - val_accuracy: 0.7120 - val_loss: 2.1431\n",
            "Epoch 37/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 0.0780 - val_accuracy: 0.7120 - val_loss: 2.0274\n",
            "Epoch 38/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9946 - loss: 0.0746 - val_accuracy: 0.7143 - val_loss: 2.0759\n",
            "Epoch 39/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0733 - val_accuracy: 0.7234 - val_loss: 1.9889\n",
            "Epoch 40/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0768 - val_accuracy: 0.7166 - val_loss: 1.7819\n",
            "Epoch 41/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0837 - val_accuracy: 0.7188 - val_loss: 1.9365\n",
            "Epoch 42/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0780 - val_accuracy: 0.7211 - val_loss: 2.0807\n",
            "Epoch 43/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9939 - loss: 0.0741 - val_accuracy: 0.7234 - val_loss: 1.8035\n",
            "Epoch 44/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.0725 - val_accuracy: 0.7166 - val_loss: 2.0323\n",
            "Epoch 45/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0713 - val_accuracy: 0.7143 - val_loss: 2.1977\n",
            "Epoch 46/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0723 - val_accuracy: 0.7234 - val_loss: 1.9528\n",
            "Epoch 47/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9907 - loss: 0.0786 - val_accuracy: 0.7120 - val_loss: 2.1349\n",
            "Epoch 48/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0850 - val_accuracy: 0.7166 - val_loss: 2.0477\n",
            "Epoch 49/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9964 - loss: 0.0664 - val_accuracy: 0.7211 - val_loss: 2.2520\n",
            "Epoch 50/50\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0632 - val_accuracy: 0.7211 - val_loss: 2.0885\n",
            "9/9 - 0s - 3ms/step - accuracy: 0.9891 - loss: 0.1305\n",
            "\n",
            "Test accuracy: 0.989051103591919\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
          ]
        }
      ],
      "source": [
        "\n",
        "history = model.fit(X_train_smote, y_train_smote, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"\\nTest accuracy: {test_acc}\")\n",
        "\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calcular métricos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall: 0.9890510948905109\n",
            "Precision-Recall AUC: 0.968974344837061\n",
            "F1 Score: 0.9879845694187057\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.33      0.40         3\n",
            "           1       0.98      0.99      0.98        96\n",
            "           2       1.00      1.00      1.00       175\n",
            "\n",
            "    accuracy                           0.99       274\n",
            "   macro avg       0.83      0.77      0.79       274\n",
            "weighted avg       0.99      0.99      0.99       274\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Recall: {recall}\")\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob[:, 1], pos_label=1)  # Adjust for the class of interest\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"Precision-Recall AUC: {pr_auc}\")\n",
        "\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluación con Algoritmos de scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNMRHGcsO_rG"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_algorithms(X, y):\n",
        "    # Split the data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Apply SMOTE to balance the classes\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Check the class distribution\n",
        "    print(\"Original class distribution:\")\n",
        "    print(y_train.value_counts())\n",
        "    print(\"\\nBalanced class distribution:\")\n",
        "    print(y_train_balanced.value_counts())\n",
        "\n",
        "    # Define the models to be used\n",
        "    models = {\n",
        "        'Logistic Regression': LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs'),\n",
        "        'Decision Tree': DecisionTreeClassifier(),\n",
        "        'Support Vector Classifier': SVC(),\n",
        "        'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "        'Naive Bayes': GaussianNB(),\n",
        "        'Linear Discriminant Analysis': LinearDiscriminantAnalysis()\n",
        "    }\n",
        "\n",
        "    # Initialize a list to store the results\n",
        "    results = []\n",
        "\n",
        "    # Train and evaluate each model\n",
        "    for name, model in models.items():\n",
        "        start_time = time.time()\n",
        "        model.fit(X_train_balanced, y_train_balanced)\n",
        "        training_time = time.time() - start_time\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate performance metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "        # Append the results\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Accuracy': accuracy,\n",
        "            'F1 Score': f1,\n",
        "            'Training Time (s)': training_time\n",
        "        })\n",
        "\n",
        "    # Convert results to a DataFrame and display\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGWuOPaHPFS7",
        "outputId": "4c9f12b5-cc22-4216-f772-3dedc7e5bc9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original class distribution:\n",
            "EscalaRiesgo\n",
            "C    645\n",
            "B    305\n",
            "A      9\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Balanced class distribution:\n",
            "EscalaRiesgo\n",
            "C    645\n",
            "B    645\n",
            "A    645\n",
            "Name: count, dtype: int64\n",
            "                          Model  Accuracy  F1 Score  Training Time (s)\n",
            "0           Logistic Regression  0.963504  0.964074           0.386540\n",
            "1                 Decision Tree  0.936740  0.935397           0.083869\n",
            "2     Support Vector Classifier  0.861314  0.856127           0.136673\n",
            "3           K-Nearest Neighbors  0.664234  0.674319           0.006041\n",
            "4                   Naive Bayes  0.953771  0.962749           0.017494\n",
            "5  Linear Discriminant Analysis  0.956204  0.956470           0.067245\n"
          ]
        }
      ],
      "source": [
        "target_column = 'EscalaRiesgo'\n",
        "\n",
        "train_and_evaluate_algorithms(X, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBCZXA21nxjN"
      },
      "source": [
        "# 3. [Ajuste Fino](##AjusteFino)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxQBYeCa5LRd"
      },
      "source": [
        "De acuerdo a la métrica F1 Score, los 2 mejores modelos son:\n",
        "- Logistic Regression\n",
        "- Nayve Bayes\n",
        "\n",
        "Con base en estos dos modelos, realizaremos el afinamiento de hiperparámetros. Definimos una función que realizará el afinamiento de hiperparámetros con base a los 2 modelos elegidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-WHGJy6o4oF4"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_algorithms(X, y):\n",
        "    # Split the data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Apply SMOTE to balance the classes\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Check the class distribution\n",
        "    print(\"Original class distribution:\")\n",
        "    print(y_train.value_counts())\n",
        "    print(\"\\nBalanced class distribution:\")\n",
        "    print(y_train_balanced.value_counts())\n",
        "\n",
        "    # Define the models to be used\n",
        "    models = {\n",
        "        'Logistic Regression': LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs'),\n",
        "        'Naive Bayes': GaussianNB(),\n",
        "    }\n",
        "\n",
        "    # Initialize a list to store the results\n",
        "    results = []\n",
        "\n",
        "    # Train and evaluate each model\n",
        "    for name, model in models.items():\n",
        "        start_time = time.time()\n",
        "        model.fit(X_train_balanced, y_train_balanced)\n",
        "        training_time = time.time() - start_time\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate performance metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "        # Append the results\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Accuracy': accuracy,\n",
        "            'F1 Score': f1,\n",
        "            'Training Time (s)': training_time\n",
        "        })\n",
        "\n",
        "    # Hyperparameter tuning for Logistic Regression\n",
        "    log_reg = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
        "    log_reg_params = {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'solver': ['newton-cg', 'lbfgs', 'saga']\n",
        "    }\n",
        "    log_reg_grid = GridSearchCV(log_reg, log_reg_params, cv=5, scoring='f1_weighted')\n",
        "    start_time = time.time()\n",
        "    log_reg_grid.fit(X_train_balanced, y_train_balanced)\n",
        "    training_time = time.time() - start_time\n",
        "    log_reg_best = log_reg_grid.best_estimator_\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = log_reg_best.predict(X_test)\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    # Append the results\n",
        "    results.append({\n",
        "        'Model': 'Logistic Regression (Tuned)',\n",
        "        'Accuracy': accuracy,\n",
        "        'F1 Score': f1,\n",
        "        'Training Time (s)': training_time\n",
        "    })\n",
        "\n",
        "    # Hyperparameter tuning for Naive Bayes (Gaussian)\n",
        "    naive_bayes = GaussianNB()\n",
        "    nb_params = {\n",
        "        'var_smoothing': [1e-09, 1e-08, 1e-07, 1e-06, 1e-05]\n",
        "    }\n",
        "    nb_grid = GridSearchCV(naive_bayes, nb_params, cv=5, scoring='f1_weighted')\n",
        "    start_time = time.time()\n",
        "    nb_grid.fit(X_train_balanced, y_train_balanced)\n",
        "    training_time = time.time() - start_time\n",
        "    nb_best = nb_grid.best_estimator_\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = nb_best.predict(X_test)\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    # Append the results\n",
        "    results.append({\n",
        "        'Model': 'Naive Bayes (Tuned)',\n",
        "        'Accuracy': accuracy,\n",
        "        'F1 Score': f1,\n",
        "        'Training Time (s)': training_time\n",
        "    })\n",
        "\n",
        "    # Convert results to a DataFrame and display\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oxQEgMK7Eio",
        "outputId": "9b5992cb-d8fa-4b20-bbe0-645380e06de4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original class distribution:\n",
            "EscalaRiesgo\n",
            "C    645\n",
            "B    305\n",
            "A      9\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Balanced class distribution:\n",
            "EscalaRiesgo\n",
            "C    645\n",
            "B    645\n",
            "A    645\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                         Model  Accuracy  F1 Score  Training Time (s)\n",
            "0          Logistic Regression  0.963504  0.964074           0.363115\n",
            "1                  Naive Bayes  0.953771  0.962749           0.016687\n",
            "2  Logistic Regression (Tuned)  0.961071  0.961925         110.308201\n",
            "3          Naive Bayes (Tuned)  0.953771  0.962749           0.500227\n"
          ]
        }
      ],
      "source": [
        "train_and_evaluate_algorithms(X, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhJjQvOR4N80"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
